{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "X_train = [[1,      4], \n",
    "           [np.nan, 3], \n",
    "           [7,      8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 4.]\n",
      " [4. 3.]\n",
      " [7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# Limpieza de datos: imputación valores ausentes (modelo)\n",
    "imputer = SimpleImputer(strategy='mean') # Utilizamos la estrategia de la media\n",
    "\n",
    "# Aplicar los métodos \"fit\" y \"transform\" para imputar los valores pérdidos de X_train\n",
    "X_train_clean = imputer.fit_transform(X_train)\n",
    "print(X_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. 10.]\n",
      " [ 6.  5.]\n",
      " [ 8.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Imputación de valores ausentes sobre el conjunto de test\n",
    "X_test = [[np.nan, 10], \n",
    "          [6,      np.nan], \n",
    "          [8,      2]]\n",
    "\n",
    "# Imputar los datos del conjunto de test\n",
    "X_test_clean = imputer.transform(X_test)\n",
    "print(X_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
      "0            39.1         18.7          181.0    3750.0        0\n",
      "1            39.5         17.4          186.0    3800.0        0\n",
      "2            40.3         18.0          195.0    3250.0        0\n",
      "3             NaN          NaN            NaN       NaN        0\n",
      "4            36.7         19.3          193.0    3450.0        0\n",
      "..            ...          ...            ...       ...      ...\n",
      "339          55.8         19.8          207.0    4000.0        2\n",
      "340          43.5         18.1          202.0    3400.0        2\n",
      "341          49.6         18.2          193.0    3775.0        2\n",
      "342          50.8         19.0          210.0    4100.0        2\n",
      "343          50.2         18.7          198.0    3775.0        2\n",
      "\n",
      "[344 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar dataframe\n",
    "df = pd.read_csv(\"penguins.csv\", sep=';')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.910e+01 1.870e+01 1.810e+02 3.750e+03 0.000e+00]\n",
      " [3.950e+01 1.740e+01 1.860e+02 3.800e+03 0.000e+00]\n",
      " [4.030e+01 1.800e+01 1.950e+02 3.250e+03 0.000e+00]\n",
      " ...\n",
      " [4.960e+01 1.820e+01 1.930e+02 3.775e+03 2.000e+00]\n",
      " [5.080e+01 1.900e+01 2.100e+02 4.100e+03 2.000e+00]\n",
      " [5.020e+01 1.870e+01 1.980e+02 3.775e+03 2.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir dataframe a numpy array\n",
    "data = np.array(df)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3 271]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si existen valores ausentes\n",
    "pos_ausentes = np.unique(np.where(np.isnan(data))[0])\n",
    "print(pos_ausentes)\n",
    "print(len(pos_ausentes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos imputador con la estrategia de la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Aplicamos el imputador definido a los datos\n",
    "data_clean = imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Comprobar de nuevo si existen valores ausentes\n",
    "pos_ausentes = np.unique(np.where(np.isnan(data_clean))[0])\n",
    "print(pos_ausentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el nuevo dataset corregido\n",
    "df = pd.DataFrame(np.round(data_clean, 2), columns=[\"Culmen length\", \"Culmen depth\", \"Flipper length\", \"Body mass\", \"Especies\"])\n",
    "df.to_csv('penguins_clean.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
