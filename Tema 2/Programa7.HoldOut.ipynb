{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "iris = datasets.load_iris()\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de datos: 150 instancias y 4 atributos\n",
      "Valores de la clase: {0, 1, 2}\n",
      "[0 1 2] [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar características de la tabla de datos.\n",
    "print(\"Tabla de datos: %d instancias y %d atributos\" % (iris.data.shape[0], iris.data.shape[1]))\n",
    "print(\"Valores de la clase:\", set(iris.target))\n",
    "\n",
    "# Cuantificamos el número de instancias que contiene el dataset por clase\n",
    "valores, ocurrencias = np.unique(iris.target, return_counts=True)\n",
    "print(valores, ocurrencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ->      clases: [0 1 2]  ocurrencias:  [10  9 11]\n",
      "Training ->  clases: [0 1 2]  ocurrencias:  [40 41 39]\n"
     ]
    }
   ],
   "source": [
    "# Test: hold-out split 80-20%. # Partición externa\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Test\n",
    "valores_test, ocur_test = np.unique(y_test, return_counts=True)\n",
    "print('Test ->     ', 'clases:', valores_test, ' ocurrencias: ', ocur_test)\n",
    "\n",
    "# Training\n",
    "valores_training, ocur_training = np.unique(y_training, return_counts=True)\n",
    "print('Training -> ', 'clases:', valores_training, ' ocurrencias: ', ocur_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar las características de entrenamiento y de test\n",
    "standardizer = StandardScaler()\n",
    "X_training = standardizer.fit_transform(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ->        clases: [0 1 2]   ocurrencias: [32 30 34]\n",
      "Validation ->   clases: [0 1 2]   ocurrencias: [ 8 11  5]\n"
     ]
    }
   ],
   "source": [
    "# Validación: hold-out split 80-20%. # Partición interna\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.2, random_state=42)\n",
    "valores_train, ocur_train = np.unique(y_train, return_counts=True)\n",
    "print('Train ->      ', ' clases:', valores_train, '  ocurrencias:', ocur_train)\n",
    "\n",
    "valores_val, ocur_val = np.unique(y_val, return_counts=True)\n",
    "print('Validation -> ', ' clases:', valores_val, '  ocurrencias:', ocur_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del objeto que contiene el algoritmo de aprendizaje.\n",
    "clf = DummyClassifier(strategy='prior', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del algoritmo de aprendizaje.\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en validación:  0.20833333333333334\n",
      "Exactitud en test:  0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del algoritmo de aprendizaje con el método \"score\" que devuelve directamente la métrica de 'accuracy'\n",
    "val_accuracy = clf.score(X_val, y_val)\n",
    "print(\"Exactitud en validación: \", val_accuracy)\n",
    "\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Exactitud en test: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones de validación  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Etiquetas reales validación [1 1 0 0 0 2 1 2 2 2 1 1 1 1 1 0 2 0 1 0 1 1 0 0]\n",
      "\n",
      "Predicciones de test  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Etiquetas reales test [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las predicciones sobre conjunto de validación y de test\n",
    "y_pred_val = clf.predict(X_val)\n",
    "print('Predicciones de validación ', y_pred_val)\n",
    "print('Etiquetas reales validación', y_val)\n",
    "\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('\\nPredicciones de test ', y_pred_test)\n",
    "print('Etiquetas reales test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en validación:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Importamos un clasificador más complejo que el anterior\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir el algoritmo\n",
    "clf = SVC(C=1, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Entrenar el modelo\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calcular el accuracy y volvemos a parametrizar para mejorar los resultados\n",
    "val_accuracy = clf.score(X_val, y_val)\n",
    "print(\"Exactitud en validación: \", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en test:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calcular el accuracy en el test utilizando el mejor de los modelos anteriores. En nuestro caso, el segundo\n",
    "X_test = standardizer.transform(X_test)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Exactitud en test: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "import pickle\n",
    "with open('../models/model.pickle', 'wb') as fw:\n",
    "    pickle.dump(model, fw)\n",
    "\n",
    "# Cargar modelo\n",
    "with open('../models/model.pickle', 'rb') as fr:\n",
    "    pickle.load(fr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
